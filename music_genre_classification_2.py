# -*- coding: utf-8 -*-
"""Music Genre Classification-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dOQraT6jiLzxDEAqFpAMyrsKgRzy3NEh
"""
#
# from google.colab import drive
# drive.mount('/content/drive')

import json
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow import keras as keras

import matplotlib.pyplot as plt
import random

import librosa
import math

# path to json
DATA_PATH = "F:\\8th SEM\\mgc\\data_10.json"


def load_data(data_path):
    with open(data_path, "r") as f:
        data = json.load(f)

    # convert lists to numpy arrays
    X = np.array(data["mfcc"])
    y = np.array(data["labels"])

    print("Data succesfully loaded!")

    return X, y


# load data
X, y = load_data(DATA_PATH)

X.shape

"""**Convolutional Neural** **Network**"""

# create train, validation and test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
# X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.25)

# # add an axis to input sets
# X_train = X_train[..., np.newaxis]
# X_validation = X_validation[..., np.newaxis]
# X_test = X_test[..., np.newaxis]

X_train.shape

input_shape = (X_train.shape[1], X_train.shape[2], 1)
input_shape

# build the CNN
model_cnn = keras.Sequential()

# 1st conv layer
model_cnn.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))
model_cnn.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))
model_cnn.add(keras.layers.BatchNormalization())

# 2nd conv layer
model_cnn.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))
model_cnn.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))
model_cnn.add(keras.layers.BatchNormalization())

# 3rd conv layer
model_cnn.add(keras.layers.Conv2D(64, (2, 2), activation='relu'))
model_cnn.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))
model_cnn.add(keras.layers.BatchNormalization())

# flatten output and feed it into dense layer
model_cnn.add(keras.layers.Flatten())
model_cnn.add(keras.layers.Dense(64, activation='relu'))

# output layer
model_cnn.add(keras.layers.Dense(10, activation='softmax'))

# compile model
optimiser = keras.optimizers.Adam(learning_rate=0.001)
model_cnn.compile(optimizer=optimiser,
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

model_cnn.summary()

# train model
history = model_cnn.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=100)

# evaluate model on Test Set
test_loss, test_acc = model_cnn.evaluate(X_test, y_test, verbose=2)
print('\nTest accuracy:', test_acc)

model_cnn.save("F:\\8th SEM\\mgc\\Music_Genre_10_CNN")

# It can be used to reconstruct the model identically.
reconstructed_model = keras.models.load_model("F:\\8th SEM\\mgc\\Music_Genre_10_CNN")

"""**Prediction on Test Set**"""

for n in range(10):
    # pick a sample to predict from the test set
    X_to_predict = X_test[n]
    y_to_predict = y_test[n]

    print("\nReal Genre:", y_to_predict)

    X_to_predict = X_to_predict[np.newaxis, ...]

    prediction = model_cnn.predict(X_to_predict)

    # get index with max value
    predicted_index = np.argmax(prediction, axis=1)

    print("Predicted Genre:", int(predicted_index))

"""**Prediction on New Songs**"""
# Audio files pre-processing
def process_input(audio_file, track_duration):
    SAMPLE_RATE = 22050
    NUM_MFCC = 13
    N_FTT = 2048
    HOP_LENGTH = 512
    TRACK_DURATION = track_duration  # measured in seconds
    SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION
    NUM_SEGMENTS = 10
    samples_per_segment = int(SAMPLES_PER_TRACK / NUM_SEGMENTS)
    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / HOP_LENGTH)
    signal, sample_rate = librosa.load(audio_file, sr=SAMPLE_RATE)
    for d in range(10):
        # calculate start and finish sample for current segment
        start = samples_per_segment * d
        finish = start + samples_per_segment
        # extract mfcc
        mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=NUM_MFCC, n_fft=N_FTT,
                                    hop_length=HOP_LENGTH)
        mfcc = mfcc.T
        return mfcc

genre_dict = {1: "blues", 2: "classical", 3: "country", 4: "disco", 5: "hip-hop", 6: "jazz", 7: "metal", 8: "pop",
              9: "reggae", 10: "rock"}

new_input_mfcc = process_input("/content/drive/MyDrive/MGC Dataset/MP3 Test/t1.mp3", 30)

X_to_predict = new_input_mfcc[np.newaxis, ..., np.newaxis]

prediction = model_cnn.predict(X_to_predict)

# get index with max value
predicted_index = np.argmax(prediction)
print("Predicted Genre: ", genre_dict[int(predicted_index)])
